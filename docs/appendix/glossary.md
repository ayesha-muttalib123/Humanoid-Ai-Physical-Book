---
sidebar_label: Glossary
---

# Glossary: Physical AI & Humanoid Robotics

## A

**Actuator**: A mechanical device for moving or controlling a mechanism or system. In robotics, actuators convert energy (often electrical) into physical motion.

**Affordance**: A property of an object or environment that defines and constrains how it can be used. In embodied AI, affordances emerge from the interaction between the agent's capabilities and environmental properties.

## B

**Behavior-Based Robotics**: An approach to robotics that emphasizes the design of autonomous robots using task-achieving behaviors as the fundamental building blocks.

## C

**Cognitive Coupling**: The tight integration between an agent's cognitive processes and its environment, where the environment becomes part of the cognitive system.

**Control Loop**: A feedback mechanism in which a system continuously monitors its output and adjusts its behavior to maintain a desired state.

## D

**Deep Reinforcement Learning**: A type of machine learning that combines deep learning with reinforcement learning, allowing agents to learn complex behaviors through trial and error.

**Dexterous Manipulation**: The skillful and precise handling of objects using robotic hands or grippers, often involving complex finger movements and force control.

## E

**Embodied AI**: Artificial intelligence systems that are designed to interact with the physical world through a body or robot platform.

**Embodied Cognition**: The theory that cognitive processes are deeply rooted in the body's interactions with the environment.

**Enaction**: A theory of cognition proposing that it arises through a dynamic interaction between an acting organism and its environment.

## F

**Forward Kinematics**: The computation of the position and orientation of a robot's end-effector based on the known joint angles.

## G

**Gazebo**: A physics-based 3D simulation environment for robotics and autonomous systems.

## H

**Humanoid Robot**: A robot with a physical structure similar to that of a human body, typically having a head, torso, two arms, and two legs.

## I

**Inverse Kinematics**: The computation of the joint angles required to achieve a desired position and orientation of a robot's end-effector.

**IRL (Inverse Reinforcement Learning)**: A technique to learn the reward function from expert demonstrations rather than specifying it explicitly.

## L

**Locomotion**: The ability to move from one place to another, a fundamental capability for mobile robots.

## M

**Manipulation**: The ability to purposefully control objects in the environment using robotic effectors.

**Morphological Computation**: The idea that the physical properties of a robot's body can contribute to its computational processes, reducing the burden on the controller.

## N

**Neuromorphic Computing**: Computing systems designed to mimic the neural structure and functioning of the brain, often used in embodied AI systems for efficiency.

## P

**Perception-Action Cycle**: The continuous loop where an agent perceives its environment, decides how to act, acts, and then perceives the effects of its actions.

**Proprioception**: The sense of the relative position of one's own parts of the body and strength of effort being employed in movement.

## R

**Reactive System**: A system that responds directly to environmental stimuli without maintaining an internal state or planning ahead.

**Robot Operating System (ROS)**: Flexible framework for writing robot software, providing a collection of tools, libraries, and conventions for building complex and robust robot behavior across a wide variety of robot platforms.

**ROS 2**: The second generation of the Robot Operating System, offering improved security, real-time support, and distributed computing capabilities.

## S

**Sensorimotor**: Relating to both sensation and motor action, emphasizing the tight coupling between perception and action.

**Sim-to-Real Transfer**: The process of transferring policies or models trained in simulation to real-world robotic systems.

**SLAM (Simultaneous Localization and Mapping)**: The computational problem of constructing or updating a map of an unknown environment while simultaneously keeping track of an agent's location within it.

## T

**Teleoperation**: The remote operation of a robot, where a human operator controls the robot's actions from a distance.

## U

**URDF (Unified Robot Description Format)**: An XML format for representing a robot model in ROS, defining the robot's physical and visual properties.

## V

**Visual Servoing**: A control strategy that uses visual feedback to control the motion of a robot.

## W

**Whole-Body Control**: An approach to robot control that considers the entire robot as a single system, optimizing all degrees of freedom simultaneously to achieve multiple tasks.

## Y

**YAML (YAML Ain't Markup Language)**: A human-readable data serialization format commonly used for configuration files in robotics frameworks like ROS.